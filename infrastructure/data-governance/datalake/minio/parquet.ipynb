{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d384e534-4114-416f-be37-3c46921b4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "            .appName('PySparkMinIO')\n",
    "            .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.1,\"\n",
    "                                            \"com.amazonaws:aws-java-sdk-bundle:1.12.709\")\n",
    "            .config(\"spark.hadoop.fs.s3a.access.key\", \"andreyolv\")\n",
    "            .config(\"spark.hadoop.fs.s3a.secret.key\", \"andreyolv\")\n",
    "            .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio.minio:9000\")\n",
    "            .config(\"spark.hadoop.fs.s3a.path.style.access\", True)\n",
    "            .config(\"spark.hadoop.fs.s3a.fast.upload\", True)\n",
    "            .config(\"spark.hadoop.fs.s3a.multipart.size\", 104857600)\n",
    "            .config(\"fs.s3a.connection.maximum\", 100)\n",
    "            .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "            .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbd6fc-7f17-492f-9330-fc25aa41249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a schema for your dataframe\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"phone_number\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Use the Faker library to generate data for your dataframe\n",
    "data = [\n",
    "    ('Andrey', 'andrey@gmail.com', 'Rua dos Can√°rios', '4199991111'),\n",
    "    ('Joao', 'jaozinho@gmail.com', 'Rua dos Pardais', '4199992222'),\n",
    "    ('Amora', 'amorinha@gmail.com', 'Rua das Andorinhas', '4199993333'),\n",
    "    ('Lucy', 'lucymara@gmail.com', 'Rua dos Papagaios', '4199994444'),]\n",
    "\n",
    "# Create a PySpark dataframe from your data and schema\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Show your dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc23f3-a678-44c9-87ed-e9ee9aaf1bd1",
   "metadata": {},
   "source": [
    "## Save Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab9a3d-ddfa-4719-98de-e02452b89d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_location = 's3a://lakehouse/parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33397b-ca92-4a85-932a-14bf18305194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode('overwrite').option('header', True).parquet(s3_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce81ad-68d2-4a78-97d2-7dfd3576a85b",
   "metadata": {},
   "source": [
    "## Load Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4340b7-0ae2-47b6-9c8b-e5d9edeb5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"parquet\").load(s3_location).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b8cbf-14fc-4fc8-b535-208ea9fde69a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
