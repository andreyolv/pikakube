{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"DeltaSession\") \\\n",
    "            .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\") \\\n",
    "            .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "            .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the schema for a DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"city\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create a DataFrame using the schema\n",
    "data = [(1, \"Alice\", 25, \"New York\"), \n",
    "        (2, \"Bob\", 30, \"San Francisco\"), \n",
    "        (3, \"Charlie\", 35, \"Chicago\")]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").saveAsTable(\"02deltatable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeltaTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [forPath](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.forPath)\n",
    "\n",
    "forPath(sparkSession: pyspark.sql.session.SparkSession, path: str, hadoopConf: Dict[str, str] = {}) → delta.tables.DeltaTable\n",
    "Instantiate a DeltaTable object representing the data at the given path, If the given path is invalid (i.e. either no table exists or an existing table is not a Delta table), it throws a not a Delta table error.\n",
    "\n",
    "Parameters:\t\n",
    "- sparkSession (pyspark.sql.SparkSession) – SparkSession to use for loading the table\n",
    "- hadoopConf (optional dict with str as key and str as value.) – Hadoop configuration starting with “fs.” or “dfs.” will be picked up by DeltaTable to access the file system when executing queries. Other configurations will not be allowed.\n",
    "\n",
    "Returns:\t\n",
    "loaded Delta table\n",
    "\n",
    "Return type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt = DeltaTable.forPath(spark, 'extract/01delta')\n",
    "\n",
    "dt.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [forName](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.forName)\n",
    "\n",
    "forName(sparkSession: pyspark.sql.session.SparkSession, tableOrViewName: str) → delta.tables.DeltaTable\n",
    "Instantiate a DeltaTable object using the given table or view name. If the given tableOrViewName is invalid (i.e. either no table exists or an existing table is not a Delta table), it throws a not a Delta table error.\n",
    "\n",
    "The given tableOrViewName can also be the absolute path of a delta datasource (i.e. delta.`path`), If so, instantiate a DeltaTable object representing the data at the given path (consistent with the forPath).\n",
    "\n",
    "Parameters:\t\n",
    "- sparkSession – SparkSession to use for loading the table\n",
    "- tableOrViewName – name of the table or view\n",
    "\n",
    "Returns:\t\n",
    "loaded Delta table\n",
    "\n",
    "Return type:\t\n",
    "DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt = DeltaTable.forName(spark, \"02deltatable\")\n",
    "dt.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE 02deltatable\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [isDeltaTable](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.isDeltaTable)\n",
    "\n",
    "isDeltaTable(sparkSession: pyspark.sql.session.SparkSession, identifier: str) → bool\n",
    "Check if the provided identifier string, in this case a file path, is the root of a Delta table using the given SparkSession.\n",
    "\n",
    "Parameters:\t\n",
    "- sparkSession – SparkSession to use to perform the check\n",
    "- path – location of the table\n",
    "\n",
    "Returns:\t\n",
    "If the table is a delta table or not\n",
    "\n",
    "Return type:\t\n",
    "bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DeltaTable.isDeltaTable(spark, 'extract/01delta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM 02deltatable\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM delta.`/home/jovyan/delta/extract/01delta/`\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeltaTable.forName(spark, \"02deltatable\").toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeltaTable.forPath(spark, 'extract/01delta').toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TBLPROPERTIES delta.`/home/jovyan/delta/extract/01delta/`\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [detail](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.detail)\n",
    "\n",
    "Get the details of a Delta table such as the format, name, and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE DETAIL 02deltatable\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.detail().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [history](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.history)\n",
    "\n",
    "Get the information of the latest limit commits on this table as a Spark DataFrame. The information is in reverse chronological order.\n",
    "\n",
    "Parameters:\tlimit – Optional, number of latest commits to returns in the history.\n",
    "\n",
    "Returns:\tTable’s commit history. See the online Delta Lake documentation for more details.\n",
    "\n",
    "Return type:\tpyspark.sql.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE HISTORY 02deltatable\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO 02deltatable (id, name, age, city)\n",
    "VALUES (1, 'Marcelo', 5, 'Sao Paulo')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE HISTORY 02deltatable\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "DESCRIBE HISTORY 02deltatable LIMIT 1\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.history().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.history(1).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE 02deltatable\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE TABLE EXTENDED 02deltatable\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
