{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"DeltaSession\") \\\n",
    "            .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\") \\\n",
    "            .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "            .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL - Create DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS 02deltatable2 (\n",
    "  id INT,\n",
    "  name STRING,\n",
    "  age INT,\n",
    "  city STRING\n",
    ") USING DELTA\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TBLPROPERTIES 02deltatable2\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM 02deltatable2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python - Create DeltaTable\n",
    "\n",
    "4 options:\n",
    "- create\n",
    "- createIfNotExists\n",
    "- replace\n",
    "- createOrReplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [create](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.create)\n",
    "\n",
    "classmethod create(sparkSession: Optional[pyspark.sql.session.SparkSession] = None) → delta.tables.DeltaTableBuilder\n",
    "\n",
    "Return DeltaTableBuilder object that can be used to specify the table name, location, columns, partitioning columns, table comment, and table properties to create a Delta table, error if the table exists (the same as SQL CREATE TABLE).\n",
    "\n",
    "Parameters:\n",
    "- sparkSession – SparkSession to use for creating the table\n",
    "\n",
    "## [createIfNotExists](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.createIfNotExists)\n",
    "\n",
    "classmethod createIfNotExists(sparkSession: Optional[pyspark.sql.session.SparkSession] = None) → delta.tables.DeltaTableBuilder\n",
    "\n",
    "Return DeltaTableBuilder object that can be used to specify the table name, location, columns, partitioning columns, table comment, and table properties to create a Delta table, if it does not exists (the same as SQL CREATE TABLE IF NOT EXISTS).\n",
    "\n",
    "Parameters:\n",
    "- sparkSession – SparkSession to use for creating the table\n",
    "\n",
    "## [replace](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.replace)\n",
    "\n",
    "classmethod replace(sparkSession: Optional[pyspark.sql.session.SparkSession] = None) → delta.tables.DeltaTableBuilder\n",
    "\n",
    "Return DeltaTableBuilder object that can be used to specify the table name, location, columns, partitioning columns, table comment, and table properties to replace a Delta table, error if the table doesn’t exist (the same as SQL REPLACE TABLE).\n",
    "\n",
    "Parameters:\n",
    "- sparkSession – SparkSession to use for creating the table\n",
    "\n",
    "## [createOrReplace](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.createOrReplace)\n",
    "\n",
    "classmethod createOrReplace(sparkSession: Optional[pyspark.sql.session.SparkSession] = None) → delta.tables.DeltaTableBuilder\n",
    "\n",
    "Return DeltaTableBuilder object that can be used to specify the table name, location, columns, partitioning columns, table comment, and table properties replace a Delta table, error if the table doesn’t exist (the same as SQL REPLACE TABLE).\n",
    "\n",
    "See DeltaTableBuilder for a full description and examples of this operation.\n",
    "\n",
    "Parameters:\n",
    "- sparkSession – SparkSession to use for creating the table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [tableName](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTableBuilder.tableName)\n",
    "\n",
    "tableName(identifier: str) → delta.tables.DeltaTableBuilder\n",
    "\n",
    "Specify the table name. Optionally qualified with a database name [database_name.] table_name.\n",
    "\n",
    "Parameters:\n",
    "- identifier (str) – the table name\n",
    "\n",
    "## [location](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTableBuilder.location)\n",
    "\n",
    "location(location: str) → delta.tables.DeltaTableBuilder\n",
    "\n",
    "Specify the path to the directory where table data is stored, which could be a path on distributed storage.\n",
    "\n",
    "Parameters:\n",
    "-location (str) – the data stored location\n",
    "\n",
    "## [comment](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTableBuilder.comment)\n",
    "\n",
    "comment(comment: str) → delta.tables.DeltaTableBuilder\n",
    "\n",
    "Comment to describe the table.\n",
    "\n",
    "Parameters:\n",
    "- comment (str) – the table comment\n",
    "\n",
    "## [addColumn](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTableBuilder.addColumn)\n",
    "\n",
    "addColumn(colName: str, dataType: Union[str, pyspark.sql.types.DataType], nullable: bool = True, generatedAlwaysAs: Optional[str] = None, comment: Optional[str] = None) → delta.tables.DeltaTableBuilder\n",
    "\n",
    "Specify a column in the table\n",
    "\n",
    "Parameters:\n",
    "- colName (str) – the column name\n",
    "- dataType (str or pyspark.sql.types.DataType) – the column data type\n",
    "- nullable (bool) – whether column is nullable\n",
    "- generatedAlwaysAs (str) – a SQL expression if the column is always generated as a function of other columns. See online documentation for details on Generated Columns.\n",
    "- comment (str) – the column comment\n",
    "\n",
    "## [partitionedBy](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTableBuilder.partitionedBy)\n",
    "\n",
    "partitionedBy(*cols) → delta.tables.DeltaTableBuilder\n",
    "\n",
    "Specify columns for partitioning\n",
    "\n",
    "Parameters:\n",
    "-cols (str or list name of columns) – the partitioning cols\n",
    "\n",
    "## [property](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTableBuilder.property)\n",
    "\n",
    "property(key: str, value: str) → delta.tables.DeltaTableBuilder\n",
    "\n",
    "Specify a table property\n",
    "\n",
    "Parameters:\n",
    "- key – the table property key\n",
    "\n",
    "## [execute](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTableBuilder.execute)\n",
    "execute() → delta.tables.DeltaTable\n",
    "\n",
    "Execute Table Creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(DeltaTable\n",
    "    .createOrReplace(spark)\n",
    "    .tableName(\"02deltatable3\")\n",
    "    .addColumn(\"id\", \"INT\")\n",
    "    .addColumn(\"name\", \"STRING\")\n",
    "    .addColumn(\"age\", \"INT\")\n",
    "    .addColumn(\"city\", \"STRING\", comment = \"cityWorld\")\n",
    "    .property(\"description\", \"table with people data\")\n",
    "    .property(\"abc\", \"123\")\n",
    "    .partitionedBy(\"id\")\n",
    "    .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TBLPROPERTIES 02deltatable3\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE 02deltatable3\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM 02deltatable3\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO 02deltatable3 (id, name, age, city)\n",
    "VALUES (1, 'Marcelo', 5, 'Sao Paulo')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM 02deltatable3\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE TABLE 02deltatable3like LIKE 02deltatable3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE 02deltatable3like\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM 02deltatable3like\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE TABLE 02deltatableclone SHALLOW CLONE 02deltatable3\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM 02deltatable3\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DeltaTable.forName(spark, \"02deltatableclone\")\n",
    "dt.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.history().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO 02deltatable3 (id, name, age, city)\n",
    "VALUES (2, 'Velero', 15, 'Sao Paulo')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM 02deltatable3\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DeltaTable.forName(spark, \"02deltatableclone\")\n",
    "dt.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO 02deltatableclone (id, name, age, city)\n",
    "VALUES (4, 'Ted', 54, 'Sao Paulo')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DeltaTable.forName(spark, \"02deltatableclone\")\n",
    "dt.toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.history().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS `02deltatable3`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM 02deltatableclone\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(DeltaTable\n",
    "    .create(spark)\n",
    "    .tableName(\"02deltatable4\")\n",
    "    .addColumn(\"id\", \"INT\")\n",
    "    .addColumn(\"name\", \"STRING\")\n",
    "    .addColumn(\"age\", \"INT\")\n",
    "    .addColumn(\"city\", \"STRING\", comment = \"cityWorld\")\n",
    "    .addColumn(\"country\", \"STRING\", generatedAlwaysAs=\"'Brazil'\")\n",
    "    .addColumn(\"age-5\", \"INT\", generatedAlwaysAs=\"age - 5\")\n",
    "    .addColumn(\"name-city\", \"STRING\", generatedAlwaysAs=\"CONCAT('name', '-','city')\")\n",
    "    .addColumn(\"age_string\", \"STRING\", generatedAlwaysAs=\"CAST(age as STRING)\")\n",
    "    .property(\"description\", \"table with people data\")\n",
    "    .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeltaTable.forName(spark, \"02deltatable4\").toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for a DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"city\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create a DataFrame using the schema\n",
    "data = [(1, \"Alice\", 25, \"New York\"), \n",
    "        (2, \"Bob\", 30, \"San Francisco\"), \n",
    "        (3, None, 35, \"Chicago\")]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"append\").format(\"delta\").saveAsTable(\"02deltatable4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM 02deltatable4\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE 02deltatable4\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
