{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab0b2f9-5116-4e2b-855e-dea6a14a9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "# https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.3_2.12/\n",
    "# https://iceberg.apache.org/multi-engine-support/#apache-spark\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"etl-device-subscription\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.1,\"\n",
    "                                    \"com.amazonaws:aws-java-sdk-bundle:1.12.709,\"\n",
    "                                    \"org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0,\"\n",
    "            )\n",
    "    # S3 / Minio\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"andreyolv\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"andreyolv\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio.minio:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", True)\n",
    "    .config(\"spark.hadoop.fs.s3a.fast.upload\", True)\n",
    "    .config(\"spark.hadoop.fs.s3a.multipart.size\", 104857600)\n",
    "    .config(\"fs.s3a.connection.maximum\", 100)\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "    # Iceberg\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .config(\"spark.sql.catalog.owshq\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.owshq.s3.endpoint\", \"http://minio.minio:9000\")\n",
    "    # Catalog on S3\n",
    "    .config(\"spark.sql.catalog.owshq.type\", \"hadoop\")\n",
    "    .config(\"spark.sql.catalog.owshq.warehouse\", \"s3a://lakehouse/iceberg\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d432054-44bc-4464-911e-e2141c8d29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_table_iceberg = spark.sql(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS owshq.db.example \n",
    "        (\n",
    "           id int, \n",
    "           name string,\n",
    "           age int,\n",
    "           city string,\n",
    "           __op string\n",
    "        ) \n",
    "        USING iceberg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa0c25c-9b63-492f-aae2-cd6e05da7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for a DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"__op\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create a DataFrame using the schema\n",
    "data = [(1, \"Alice\", 25, \"New York\", \"r\"), \n",
    "        (2, \"Joao\", 30, \"San Francisco\", \"r\"), \n",
    "        (3, \"Flavio\", 21, \"Sao Paulo\", \"r\")]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "(df.write\n",
    " .format(\"iceberg\")\n",
    " .mode(\"overwrite\")\n",
    " .saveAsTable(\"owshq.db.example\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e568c9-111a-4164-955e-16d2f8ff7605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- __op: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.format(\"iceberg\").load(\"owshq.db.example\")\n",
    "\n",
    "df2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
