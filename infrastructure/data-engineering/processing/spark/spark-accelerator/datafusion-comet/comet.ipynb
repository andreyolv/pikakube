{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c6c3f9e-0ca7-492e-809b-b47fcac139ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.3.2\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 17.0.11\n",
      "Branch HEAD\n",
      "Compiled by user liangchi on 2023-02-10T19:57:40Z\n",
      "Revision 5103e00c4ce5fcc4264ca9c4df12295d42557af6\n",
      "Url https://github.com/apache/spark\n",
      "Type --help for more information.\n"
     ]
    }
   ],
   "source": [
    "!pyspark --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81b5478-5d1c-4a08-b320-b207b8628891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: jars\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/06/19 13:34:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Create SparkSession\n",
    "spark = (SparkSession.builder\n",
    "                    .appName('PySparkSyntax')\n",
    "                     .config(\"jars\", \"comet-spark-spark3.3_2.12-0.1.0.jar\")\n",
    "                    .config(\"spark.driver.extraClassPath\", \"comet-spark-spark3.3_2.12-0.1.0.jar\")\n",
    "                    .config(\"spark.executor.extraClassPath\", \"comet-spark-spark3.3_2.12-0.1.0.jar\")\n",
    "                    .config(\"spark.sql.extensions\",\"org.apache.comet.CometSparkSessionExtensions\")\n",
    "                    .config(\"spark.comet.enabled\", \"true\")\n",
    "                    .config(\"spark.comet.exec.enabled\", \"true\")\n",
    "                    .config(\"spark.comet.exec.all.enabled\", \"true\")\n",
    "                    .config(\"spark.comet.explainFallback.enabled\", \"true\")\n",
    "                    .getOrCreate()\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80268b0b-625e-43ab-8810-1ffd4c3bfbca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/19 13:34:45 INFO src/lib.rs: Comet native library initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/06/19 13:34:45 WARN CometSparkSessionExtensions$CometExecRule: Comet cannot execute some parts of this plan natively because:\n",
      "\t- Scan ExistingRDD is not supported\n",
      "\t- CollectLimit is not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+------------------+------------+\n",
      "|  name|             email|           address|phone_number|\n",
      "+------+------------------+------------------+------------+\n",
      "|Andrey|  andrey@gmail.com|  Rua dos Canários|  4199991111|\n",
      "|  Joao|jaozinho@gmail.com|   Rua dos Pardais|  4199992222|\n",
      "| Amora|amorinha@gmail.com|Rua das Andorinhas|  4199993333|\n",
      "|  Lucy|lucymara@gmail.com| Rua dos Papagaios|  4199994444|\n",
      "+------+------------------+------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"phone_number\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Use the Faker library to generate data for your dataframe\n",
    "data = [\n",
    "    ('Andrey', 'andrey@gmail.com', 'Rua dos Canários', '4199991111'),\n",
    "    ('Joao', 'jaozinho@gmail.com', 'Rua dos Pardais', '4199992222'),\n",
    "    ('Amora', 'amorinha@gmail.com', 'Rua das Andorinhas', '4199993333'),\n",
    "    ('Lucy', 'lucymara@gmail.com', 'Rua dos Papagaios', '4199994444'),]\n",
    "\n",
    "# Create a PySpark dataframe from your data and schema\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Show your dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7f75b5-828f-4f19-a5ff-5cf5c6d60532",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/06/19 13:37:17 WARN CometSparkSessionExtensions$CometExecRule: Comet cannot execute some parts of this plan natively because Execute CreateViewCommand is not supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.explain of DataFrame[name: string, email: string, address: string, phone_number: string]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "spark.sql(\"select * from table where phone_number > 5\").explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e49b0-b4db-42ee-9e73-0d3aa5bbdb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
